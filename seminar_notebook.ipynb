{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IvQcvqbGcma0"
      },
      "source": [
        "## Install library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukUO0mOXRV5_",
        "outputId": "91b0cdc8-1cb9-4952-a77e-0838344de022"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.6 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UhIZ2iGic4mp"
      },
      "source": [
        "## Import openai library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0mBGpYjpRHvl"
      },
      "outputs": [],
      "source": [
        "import openai"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IO6Tt3fEZ8EJ"
      },
      "source": [
        "## Define OpenAI API keys"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "T66tuC9SdRQz"
      },
      "source": [
        "How to get Your Secret API?\n",
        "\n",
        "1. Go to [OpenAI Platform](https://platform.openai.com/) and login\n",
        "2. Click on Personal and then click on View API keys\n",
        "3. Now, click on ‚ÄòCreate new secret key‚Äò and copy the secret key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJv5NxEMZCY9",
        "outputId": "aaba6138-785b-4925-ea9d-e473212d1819"
      },
      "outputs": [],
      "source": [
        "api_key = \"\"\n",
        "\n",
        "openai.api_key = api_key\n",
        "%env OPENAI_API_KEY=$api_key"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "R4Hnx-U2VqMO"
      },
      "source": [
        "## Data Preparation tool\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oJdfmL5rV7z8"
      },
      "source": [
        "We can now use a data preparation tool which will suggest a few improvements to our dataset before fine-tuning. We can specify -q which auto-accepts all suggestions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPlTX6bNgLYw",
        "outputId": "4a915b92-3046-4b8d-e3d4-041179450cec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PqzBlEj0vyj_43SapZAf4dPM44R98XjF\n",
            "To: /content/data.jsonl\n",
            "100% 4.17k/4.17k [00:00<00:00, 18.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "#down file data example\n",
        "!gdown --id 1PqzBlEj0vyj_43SapZAf4dPM44R98XjF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Zuu9hi9auA5",
        "outputId": "df714201-a776-471c-aac0-5b84776bd545"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing...\n",
            "\n",
            "- Your file contains 12 prompt-completion pairs. In general, we recommend having at least a few hundred examples. We've found that performance tends to linearly increase for every doubling of the number of examples\n",
            "- All prompts end with suffix `?`\n",
            "- Your data does not contain a common ending at the end of your completions. Having a common ending string appended to the end of the completion makes it clearer to the fine-tuned model where the completion should end. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples.\n",
            "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "\n",
            "Based on the analysis we will perform the following actions:\n",
            "- [Recommended] Add a suffix ending ` END` to all completions [Y/n]: Y\n",
            "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
            "\n",
            "\n",
            "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
            "\n",
            "Wrote modified file to `data_prepared.jsonl`\n",
            "Feel free to take a look!\n",
            "\n",
            "Now use that file when fine-tuning:\n",
            "> openai api fine_tunes.create -t \"data_prepared.jsonl\"\n",
            "\n",
            "After you‚Äôve fine-tuned a model, remember that your prompt has to end with the indicator string `?` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\" END\"]` so that the generated texts ends at the expected place.\n",
            "Once your model starts training, it'll approximately take 2.61 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        }
      ],
      "source": [
        "!openai tools fine_tunes.prepare_data -f data.jsonl -q"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aj2d757iWCFl"
      },
      "source": [
        "## Fine-tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfEVFeW4WEwL",
        "outputId": "b931bb34-c586-40fc-e17e-1fac70aaa60a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found potentially duplicated files with name 'data_prepared.jsonl', purpose 'fine-tune' and size 4198 bytes\n",
            "file-Zp3j069X9X6sdKhXkJFKbA9F\n",
            "file-Ndn0jNpmiGghQim9RyFpySMX\n",
            "Enter file ID to reuse an already uploaded file, or an empty string to upload this file anyway: \n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!openai  api fine_tunes.create -t data_prepared.jsonl -m ada --n_epochs 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jr1VPA8LbY0a",
        "outputId": "d64bee3f-574b-41d6-9c8a-a456e6d8f678"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-05-04 06:39:48] Created fine-tune: ft-dezwvQnJ91HvQ5nTy7ngP3UY\n",
            "[2023-05-04 06:40:12] Fine-tune costs $0.02\n",
            "[2023-05-04 06:40:12] Fine-tune enqueued. Queue number: 0\n",
            "[2023-05-04 06:40:13] Fine-tune started\n",
            "[2023-05-04 06:40:29] Completed epoch 1/20\n",
            "[2023-05-04 06:40:31] Completed epoch 2/20\n",
            "[2023-05-04 06:40:33] Completed epoch 3/20\n",
            "[2023-05-04 06:40:35] Completed epoch 4/20\n",
            "[2023-05-04 06:40:37] Completed epoch 5/20\n",
            "[2023-05-04 06:40:38] Completed epoch 6/20\n",
            "[2023-05-04 06:40:40] Completed epoch 7/20\n",
            "[2023-05-04 06:40:42] Completed epoch 8/20\n",
            "[2023-05-04 06:40:44] Completed epoch 9/20\n",
            "[2023-05-04 06:40:46] Completed epoch 10/20\n",
            "[2023-05-04 06:40:48] Completed epoch 11/20\n",
            "[2023-05-04 06:40:50] Completed epoch 12/20\n",
            "[2023-05-04 06:40:52] Completed epoch 13/20\n",
            "[2023-05-04 06:40:54] Completed epoch 14/20\n",
            "[2023-05-04 06:40:56] Completed epoch 15/20\n",
            "[2023-05-04 06:40:58] Completed epoch 16/20\n",
            "[2023-05-04 06:41:00] Completed epoch 17/20\n",
            "[2023-05-04 06:41:02] Completed epoch 18/20\n",
            "[2023-05-04 06:41:04] Completed epoch 19/20\n",
            "[2023-05-04 06:41:06] Completed epoch 20/20\n",
            "[2023-05-04 06:41:25] Uploaded model: ada:ft-personal-2023-05-04-06-41-25\n",
            "[2023-05-04 06:41:26] Uploaded result file: file-nnHfBIt8Fod47YIJNbuvBLVY\n",
            "[2023-05-04 06:41:26] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded üéâ\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m ada:ft-personal-2023-05-04-06-41-25 -p <YOUR_PROMPT>\n"
          ]
        }
      ],
      "source": [
        "!openai api fine_tunes.follow -i ft-dezwvQnJ91HvQ5nTy7ngP3UY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9KXod-2a6Mi"
      },
      "outputs": [],
      "source": [
        "## List all created fine-tunes\n",
        "!openai api fine_tunes.list"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SlzlVhUPWuQ7"
      },
      "source": [
        "## Using the fine-tuned models\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ExgkyIKtWtWz"
      },
      "source": [
        "We will now use the fine-tuned model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvsyuCh6Wdyz"
      },
      "outputs": [],
      "source": [
        "model = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFcbT99nXBaS",
        "outputId": "d1cf1a08-db16-48ea-9c75-07d27367ee88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: mmlab ·ªü ƒë√¢u?\n",
            "Answer:  Ph√≤ng th√≠ nghi·ªám ·ªü t√≤a E, ph√≤ng E5.1\n"
          ]
        }
      ],
      "source": [
        "prompt = input(\"Input: \") + '->'\n",
        "\n",
        "completion = openai.Completion.create(\n",
        "        model=model,\n",
        "        prompt=prompt,\n",
        "        max_tokens=1024, \n",
        "        temperature=0, \n",
        "        top_p=1, \n",
        "        n=1, \n",
        "        stop=[\" END\"])\n",
        "\n",
        "print(\"Answer:\", completion.choices[0].text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
